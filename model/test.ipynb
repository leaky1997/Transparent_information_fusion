{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-10):\n",
    "        super(CustomBatchNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mean = x.mean(dim=0, keepdim=True)\n",
    "            var = x.var(dim=0, keepdim=True, unbiased=False)\n",
    "            self.running_mean = (1 - self.eps) * self.running_mean + self.eps * mean\n",
    "            self.running_var = (1 - self.eps) * self.running_var + self.eps * var\n",
    "            out = (x - mean) / (var.sqrt() + self.eps)\n",
    "        else:\n",
    "            out = (x - self.running_mean) / (self.running_var.sqrt() + self.eps)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 624, 1])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个随机输入张量\n",
    "input_tensor = torch.randn(64, 624, 1)\n",
    "\n",
    "# 创建一个CustomBatchNorm实例\n",
    "norm_layer = CustomBatchNorm(num_features=624)\n",
    "\n",
    "# 将输入张量传递给norm_layer\n",
    "output_tensor = norm_layer(input_tensor)\n",
    "\n",
    "# 打印输出张量的形状\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class SEAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512,reduction=4):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, l, c = x.size()\n",
    "        x = rearrange(x, 'b l c -> b c l')\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c,1)\n",
    "        res = x * y\n",
    "        return rearrange(res, 'b c l -> b l c')\n",
    "\n",
    "x = torch.randn(2, 128, 16)\n",
    "att = SEAttention(channel=16)\n",
    "y = att(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sinc(band, t_right):\n",
    "    y_right = torch.sin(2 * math.pi * band * t_right) / ((2 * math.pi * band * t_right) + 1e-6)\n",
    "    y_left = torch.flip(y_right, [0])\n",
    "    y = torch.cat([y_left, torch.ones(1).to(t_right.device), y_right])\n",
    "    return y\n",
    "\n",
    "def Mexh(p):\n",
    "    # p = 0.04 * p  # 将时间转化为在[-5,5]这个区间内\n",
    "    y = (1 - torch.pow(p, 2)) * torch.exp(-torch.pow(p, 2) / 2)\n",
    "\n",
    "    return y\n",
    "\n",
    "def Laplace(p):\n",
    "    A = 0.08\n",
    "    ep = 0.03\n",
    "    tal = 0.1\n",
    "    f = 50\n",
    "    w = 2 * pi * f\n",
    "    q = torch.tensor(1 - pow(ep, 2))\n",
    "    y = A * torch.exp((-ep / (torch.sqrt(q))) * (w * (p - tal))) * (-torch.sin(w * (p - tal)))\n",
    "    return y\n",
    "\n",
    "class SincConv_multiple_channel(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size, in_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size += 1\n",
    "\n",
    "        self.a_ = nn.Parameter(torch.linspace(1, 10, out_channels)).view(-1, 1)\n",
    "        self.b_ = nn.Parameter(torch.linspace(0, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        half_kernel = self.kernel_size // 2\n",
    "        time_disc = torch.linspace(-half_kernel, half_kernel, steps=self.kernel_size).to(waveforms.device)\n",
    "        self.a_ = self.a_.to(waveforms.device)\n",
    "        self.b_ = self.b_.to(waveforms.device)\n",
    "        \n",
    "        filters = []\n",
    "        for i in range(self.out_channels):\n",
    "            band = self.a_[i]\n",
    "            t_right = time_disc - self.b_[i]\n",
    "            filter = sinc(band, t_right)\n",
    "            filters.append(filter)\n",
    "\n",
    "        filters = torch.stack(filters)\n",
    "        self.filters = filters.view(self.out_channels, 1, -1)\n",
    "\n",
    "        output = []\n",
    "        for i in range(self.in_channels):\n",
    "            output.append(F.conv1d(waveforms[:, i:i+1], self.filters, stride=1, padding=half_kernel, dilation=1, bias=None, groups=1))\n",
    "        return torch.cat(output, dim=1)\n",
    "\n",
    "\n",
    "class Morlet_multiple_channel(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, in_channels=1):\n",
    "\n",
    "        super(Morlet_multiple_channel, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size - 1\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "\n",
    "        self.a_ = nn.Parameter(torch.linspace(1, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "        self.b_ = nn.Parameter(torch.linspace(0, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "\n",
    "        time_disc_right = torch.linspace(0, (self.kernel_size / 2) - 1,\n",
    "                                         steps=int((self.kernel_size / 2)))\n",
    "\n",
    "        time_disc_left = torch.linspace(-(self.kernel_size / 2) + 1, -1,\n",
    "                                        steps=int((self.kernel_size / 2)))\n",
    "\n",
    "        p1 = time_disc_right - self.b_ / self.a_\n",
    "        p2 = time_disc_left - self.b_ / self.a_\n",
    "\n",
    "        Morlet_right = Morlet(p1).to(waveforms.device)\n",
    "        Morlet_left = Morlet(p2).to(waveforms.device)\n",
    "\n",
    "        Morlet_filter = torch.cat([Morlet_left, Morlet_right], dim=1)  # 40x1x250\n",
    "\n",
    "        self.filters = (Morlet_filter).view(self.out_channels, 1, self.kernel_size).to(waveforms.device)# .cuda()\n",
    "\n",
    "        output = []\n",
    "        for i in range(self.in_channels):\n",
    "            output.append(F.conv1d(waveforms[:, i:i+1], self.filters, stride=1, padding=1, dilation=1, bias=None, groups=1))\n",
    "        return torch.cat(output, dim=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected data shape: torch.Size([50, 10])\n",
      "Selected labels shape: (50,)\n",
      "Unique labels in selected set: [0 1 2 3 4]\n",
      "Number of samples for label 0: 10\n",
      "Number of samples for label 1: 10\n",
      "Number of samples for label 2: 10\n",
      "Number of samples for label 3: 10\n",
      "Number of samples for label 4: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 假设的 select_validation_samples 函数\n",
    "def select_validation_samples(data_all, label_all, num_samples):\n",
    "    unique_labels = np.unique(label_all)\n",
    "    indices_to_keep = []\n",
    "\n",
    "    for label in unique_labels:            \n",
    "        indices = np.where(label_all == label)[0]\n",
    "        if len(indices) > num_samples:\n",
    "            chosen_indices = indices[:num_samples]\n",
    "        else:\n",
    "            chosen_indices = indices\n",
    "        indices_to_keep.extend(chosen_indices)\n",
    "\n",
    "    return data_all[indices_to_keep], label_all[indices_to_keep]\n",
    "\n",
    "# 生成模拟数据和标签\n",
    "np.random.seed(0)  # 为了可重复性\n",
    "data_all = torch.randn(100, 10)  # 假设有100个样本，每个样本10个特征\n",
    "label_all = np.random.randint(0, 5, size=(100,))  # 假设有5个类别\n",
    "\n",
    "# 调用函数\n",
    "selected_data, selected_labels = select_validation_samples(data_all, label_all, 10)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Selected data shape:\", selected_data.shape)\n",
    "print(\"Selected labels shape:\", selected_labels.shape)\n",
    "print(\"Unique labels in selected set:\", np.unique(selected_labels))\n",
    "\n",
    "# 验证每个类别的样本数是否正确\n",
    "for label in np.unique(label_all):\n",
    "    print(f\"Number of samples for label {label}: {np.sum(selected_labels == label)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LQ1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
