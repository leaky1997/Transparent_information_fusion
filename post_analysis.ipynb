{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2], [1, None])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2],[1,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# learning ############\n",
    "# from cgi import test\n",
    "# from logging import config\n",
    "# from pytorch_lightning import seed_everything\n",
    "\n",
    "# from sklearn.calibration import log\n",
    "# import torch\n",
    "# ############# config##########\n",
    "# import argparse\n",
    "# from model.TSPN import Transparent_Signal_Processing_Network\n",
    "# from trainer.trainer_basic import Basic_trainer\n",
    "# from trainer.trainer_set import trainer_set\n",
    "# # from configs.config import args\n",
    "# # from configs.config import signal_processing_modules,feature_extractor_modules\n",
    "# from configs.config import yaml_arguments,config_network\n",
    "# import os\n",
    "# # os.environ['CUDA_VISIBLE_DEVICES'] = '0' for test ##########################\n",
    "# import argparse\n",
    "\n",
    "\n",
    "# config_dir = 'configs/config_basic.yaml'\n",
    "\n",
    "\n",
    "# configs,args,path = yaml_arguments(config_dir)\n",
    "# seed_everything(args.seed)    \n",
    "# # 初始化模型\n",
    "# signal_processing_modules, feature_extractor_modules = config_network(configs,args)\n",
    "# network = Transparent_Signal_Processing_Network(signal_processing_modules, feature_extractor_modules,args)\n",
    "\n",
    "# trainer,train_dataloader, val_dataloader, test_dataloader = trainer_set(args,path)\n",
    "\n",
    "# model = Basic_trainer(network, args)\n",
    "\n",
    "# best_model_path = 'save/model_TSPN/time2024-03-12-19-26_lr0.001_epochs5_scale4_l1norm0.01_datasetTHU_018_basic_seed17/model-epoch=02-val_loss=1.7489.ckpt'\n",
    "# state_dict = torch.load(best_model_path)\n",
    "# model.load_state_dict(state_dict['state_dict'])\n",
    "\n",
    "# # 使用最佳模型进行测试\n",
    "# trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scienceplots\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 24}\n",
    "plt.style.use(['science','ieee'])\n",
    "\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "def custom_print_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        text = ' '.join(map(str, args))\n",
    "        if 'file' not in kwargs or kwargs['file'] is None:\n",
    "            sys.stdout.write(text + '\\n')\n",
    "        else:\n",
    "            kwargs['file'].write(text + '\\n')\n",
    "\n",
    "        if 'folder' in kwargs and kwargs['folder']:\n",
    "            with open(f'{kwargs[\"folder\"]}/finetune_output.log', 'a') as log_file:\n",
    "                log_file.write(text + '\\n')\n",
    "        if 'folder' in kwargs:\n",
    "            del kwargs['folder']\n",
    "        if 'file' in kwargs:\n",
    "            del kwargs['file']\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# replace print to save all print into log files\n",
    "print = custom_print_decorator(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THU1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/LQ1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: time2024-03-20-20-53_lr0.001_epochs100_scale4_l1norm0.01_datasetTHU_006_basic_seed17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# build signal processing layers\n",
      "# build feature extractor layers\n",
      "# build classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# learning ############\n",
    "from logging import config\n",
    "from pytorch_lightning import seed_everything\n",
    "import torch\n",
    "############# config##########\n",
    "import argparse\n",
    "from model.TSPN import Transparent_Signal_Processing_Network\n",
    "from trainer.trainer_basic import Basic_trainer\n",
    "from trainer.trainer_set import trainer_set\n",
    "# from configs.config import args\n",
    "# from configs.config import signal_processing_modules,feature_extractor_modules\n",
    "from configs.config import yaml_arguments,config_network\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0' # for test ##########################\n",
    "import argparse\n",
    "\n",
    "\n",
    "config_dir = 'configs/THU_006/config_TSPN.yaml'\n",
    "\n",
    "\n",
    "configs,args,path = yaml_arguments(config_dir)\n",
    "seed_everything(args.seed)    \n",
    "# 初始化模型\n",
    "signal_processing_modules, feature_extractor_modules = config_network(configs,args)\n",
    "network = Transparent_Signal_Processing_Network(signal_processing_modules, feature_extractor_modules,args)\n",
    "\n",
    "trainer,train_dataloader, val_dataloader, test_dataloader = trainer_set(args,path)\n",
    "\n",
    "model = Basic_trainer(network, args)\n",
    "\n",
    "best_model_path = 'save/task1/TSPN/model-epoch=90-val_loss=0.1671.ckpt'\n",
    "state_dict = torch.load(best_model_path)\n",
    "model.load_state_dict(state_dict['state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "# 使用最佳模型进行测试\n",
    "# trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R1——模型加噪声鲁棒性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "def wgn2(x, snr):\n",
    "    \"加随机噪声\"\n",
    "    snr = 10**(snr/10.0)\n",
    "    xpower = torch.sum(x**2)/(x.size(0)*x.size(1)*x.size(2))\n",
    "    npower = xpower / snr\n",
    "    return torch.rand(x.size()).cuda() * torch.sqrt(npower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataloader.dataset.selected_data\n",
    "y = test_dataloader.dataset.selected_labels\n",
    "y = torch.tensor(y).cuda()\n",
    "data = torch.tensor(test_dataset).cuda()\n",
    "network = model.network\n",
    "test_y = network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### TSPN #####tensor([[89,  0,  0,  0],\n",
      "        [ 0, 89,  0,  0],\n",
      "        [ 0,  0, 89,  0],\n",
      "        [ 1,  0,  0, 88]], device='cuda:0')\n",
      "noise: -5\n",
      "noise: -4\n",
      "noise: -3\n",
      "noise: -2\n",
      "noise: -1\n",
      "noise: 0\n",
      "noise: 1\n",
      "noise: 2\n",
      "noise: 3\n",
      "noise: 4\n",
      "noise: 5\n",
      "noise: 6\n",
      "noise: 7\n",
      "noise: 8\n",
      "noise: 9\n",
      "noise: 10\n",
      "##### TSPN #####[0.5, 0.5, 0.5, 0.5, 0.5056179775280899, 0.5168539325842697, 0.5112359550561798, 0.5280898876404494, 0.550561797752809, 0.5533707865168539, 0.5702247191011236, 0.6207865168539326, 0.6376404494382022, 0.6938202247191011, 0.699438202247191, 0.7219101123595506]\n"
     ]
    }
   ],
   "source": [
    "# def calculate_accuracy_list(network, data, y, noise_dblist = [-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,10],name = 'default'):\n",
    "\n",
    "noise_dblist = [-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,10]\n",
    "name = 'TSPN'\n",
    "\n",
    "out = network(data.cuda())\n",
    "metric = ConfusionMatrix(num_classes = args.num_classes,task=\"multiclass\").to(args.device)\n",
    "confusion_matrix = metric(out.argmax(dim=1),y.to(args.device))\n",
    "print(f'##### {name} #####{confusion_matrix}')\n",
    "\n",
    "TSPN_list = []\n",
    "with torch.no_grad():\n",
    "    for noise in  noise_dblist:\n",
    "        print('noise:',noise)\n",
    "        testx_noise = data.cuda() + wgn2(data,noise)\n",
    "        pred = network(testx_noise.cuda())\n",
    "        acc = (pred.argmax(dim=1) == y.to(args.device)).sum().item()/len(y)\n",
    "        TSPN_list.append(acc)\n",
    "        del testx_noise\n",
    "        del pred\n",
    "        del acc\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print(f'##### {name} #####{TSPN_list}')\n",
    "    \n",
    "    # return confusion_matrix, TSPN_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2——稀疏信号逐层可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R3——特征可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R4——泛化的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R5——few-shot的变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R6——ablation study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R7-模型parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 找到关键operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换模型啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = 'save/THU1+THU2剪枝/THU1_08/model-epoch=80-val_loss=0.1351.ckpt'\n",
    "state_dict = torch.load(best_model_path)\n",
    "model.load_state_dict(state_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "[(5, 0, 0.6832276582717896), (4, 1, 0.6496762037277222), (8, 0, 0.6139398217201233), (2, 0, 0.5453032851219177), (11, 1, 0.5221961140632629), (10, 0, 0.4633032977581024), (1, 1, 0.43911656737327576), (10, 1, 0.4051862955093384), (8, 1, 0.39819464087486267), (1, 0, 0.343097984790802), (7, 1, 0.30707433819770813), (6, 0, 0.3022373616695404), (6, 1, 0.28355446457862854), (11, 0, 0.08653438091278076), (5, 1, 0.0716138407588005), (9, 1, 0.04742050915956497), (7, 0, 0.044268567115068436), (0, 0, 0.04405688866972923), (9, 0, 0.020347952842712402), (2, 1, 0.017998160794377327)]\n",
      "layer: 1\n",
      "[(2, 0, 0.19970162212848663), (1, 4, 0.19487152993679047), (1, 0, 0.19263790547847748), (5, 1, 0.18950757384300232), (9, 0, 0.18784919381141663), (4, 10, 0.18573583662509918), (10, 9, 0.1776593029499054), (10, 0, 0.17696809768676758), (1, 5, 0.17471979558467865), (2, 7, 0.1727316975593567), (6, 6, 0.17104002833366394), (5, 8, 0.16773609817028046), (7, 0, 0.16645173728466034), (9, 1, 0.16460593044757843), (0, 7, 0.15461203455924988), (6, 9, 0.15051336586475372), (5, 5, 0.1481669694185257), (2, 8, 0.13843272626399994), (11, 4, 0.13736090064048767), (4, 7, 0.1364154815673828)]\n",
      "layer: 2\n",
      "[(8, 10, 0.256573885679245), (8, 9, 0.24616020917892456), (8, 2, 0.21589092910289764), (7, 8, 0.21128520369529724), (7, 6, 0.2086569368839264), (5, 7, 0.19985412061214447), (1, 3, 0.1983734667301178), (8, 3, 0.1907130777835846), (7, 5, 0.18525278568267822), (1, 8, 0.1799594908952713), (6, 2, 0.17558179795742035), (0, 6, 0.1725570112466812), (1, 5, 0.1724776327610016), (1, 6, 0.16894961893558502), (5, 6, 0.16757529973983765), (0, 4, 0.1614999920129776), (7, 7, 0.15936560928821564), (2, 9, 0.1561870574951172), (10, 10, 0.1548839509487152), (1, 2, 0.15142114460468292)]\n",
      "layer: 3\n",
      "[(1, 1, 0.22147130966186523), (0, 8, 0.19878505170345306), (10, 1, 0.19140321016311646), (1, 5, 0.19125089049339294), (2, 6, 0.18210577964782715), (1, 4, 0.17607206106185913), (8, 1, 0.171970933675766), (1, 7, 0.16786298155784607), (9, 11, 0.16319479048252106), (8, 4, 0.16296876966953278), (2, 5, 0.15644851326942444), (11, 1, 0.15308840572834015), (6, 9, 0.1508840024471283), (1, 8, 0.1461494415998459), (10, 8, 0.14114035665988922), (8, 7, 0.14045986533164978), (1, 6, 0.13915041089057922), (9, 3, 0.1380251944065094), (6, 2, 0.13095737993717194), (7, 11, 0.12956427037715912)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_top_k_weights(idx, layer,k = 10):\n",
    "    print('layer:',idx)\n",
    "    weight = layer.weight_connection.weight # .detach().cpu().numpy()\n",
    "    \n",
    "    # 计算权重的绝对值\n",
    "    abs_weight = torch.abs(weight)\n",
    "\n",
    "    # 将权重矩阵扁平化\n",
    "    flat_abs_weights = abs_weight.flatten()\n",
    "\n",
    "    # 使用 topk 方法找到扁平化权重中最大的 k 个元素及其索引\n",
    "    values, flat_indices = flat_abs_weights.topk(k, largest=True)\n",
    "\n",
    "    # 如果需要，将扁平化后的索引转换回原始矩阵的二维索引\n",
    "    row_indices, col_indices = np.unravel_index(flat_indices.cpu().numpy(), abs_weight.shape)\n",
    "    result_list = []\n",
    "\n",
    "    # 在循环中将每个元素的信息添加到列表中\n",
    "    for i in range(k):\n",
    "        result_list.append((row_indices[i], col_indices[i], values[i].item()))\n",
    "    return result_list\n",
    "\n",
    "layer_top_weight = {}\n",
    "for idx, layer in enumerate(network.signal_processing_layers):\n",
    "    result_list = get_top_k_weights(idx, layer,k=20)\n",
    "    layer_top_weight[f'layer:{idx}'] = result_list\n",
    "    print(result_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.训练一个模型，记录所有权重和参数的变化情况，题头是参数名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THU2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THU1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THU2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THU1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THU1 泛化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THU2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LQ1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
